{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54ae477",
   "metadata": {},
   "source": [
    "# Infarct Image Evaluation Notebook\n",
    "\n",
    "## ðŸ“Œ Overview\n",
    "**InfarctImage** is a LoRA-based model fine-tuned on **Stable Diffusion 2.1** to generate realistic images of individuals simulating a heart attack. This model was developed to facilitate synthetic dataset generation for human activity recognition and medical emergency monitoring applications.\n",
    "\n",
    "This notebook performs evaluations on models using **LPIPS**, comparing *Stable Diffusion 1.5 and 2.1* with their respective LoRA-tuned counterparts.\n",
    "\n",
    "## ðŸŽ¯ LPIPS\n",
    "LPIPS (Learned Perceptual Image Patch Similarity) is an image quality metric that assesses the perceptual similarity between two images from a human perspective. Unlike traditional metrics such as MSE (Mean Squared Error) or PSNR (Peak Signal-to-Noise Ratio), which focus on pixel-by-pixel mathematical differences, LPIPS uses pre-trained neural networks to calculate perceptual distances. These networks extract high-level features from images and measure their similarity, allowing LPIPS to be more representative of how humans perceive differences between images.\n",
    "\n",
    "In practical terms, LPIPS compares small fragments (patches) of the input images and generates a distance score. **Lower values â€‹â€‹indicate that the images are more perceptually similar, while higher values â€‹â€‹reflect greater differences**. This makes LPIPS ideal for assessing the quality of images generated by models such as Stable Diffusion, as it aligns better with human perception than traditional metrics.\n",
    "\n",
    "## âœ… Evaluation\n",
    "**Evaluation** was performed using:\n",
    "```python\n",
    "prompt = (\"Elderly man at a sports stadium surrounded by a crowd, \"\n",
    "\t\"clutching his chest with a distressed look, indicating a heart attack.\"\n",
    "\t)\n",
    "\n",
    "negative_prompt = (\n",
    "\t\"blurry, deformed face, bad anatomy, poorly drawn face, out of focus, ugly, noisy, extra fingers, \"\n",
    "\t\"distorted, grainy, worst quality, low quality, low resolution, illustration, \"\n",
    "\t\"dull, watermark, close-up, 3d, 2d, painting, sketch, render, cartoon, grain, kitsch\"\n",
    "\t)\n",
    "\n",
    "trigger = \"Person with expression of pain due to a heart attack, \"\n",
    "\n",
    "seeds = [\n",
    "\t1982408815, 2565723973, 20943342,   1098065577,  3359898783, 520125378,   581592661,   3782932107, 3010343430, 3482978058,  3039176121, 233994633,   2757580946,  549489462,   3415398733, \n",
    "\t1068130776, 1083213219, 1089832411, 1149410080,  1159437037, 1208283828,  1238348364,  1246295977,  1304378311, 1308732453,  1318764911, 1346880011,  1348685546,  1358201195,  1383757460, \n",
    "\t1384465663, 1395674011, 1406186486, 1416263893,  1464337940, 1481286912,  1487936185,  149839352,   1543054303, 1546229499,  1558024410, 1568821309,  1627952534,  1629369529,  1668527559,\n",
    "\t1730357672, 1751671856, 1799657764, 1820327791,  1847311362, 1851968161,  1869066466,  1921870256,  1960219230, 1962662508,  1968185403, 2003417982,  2113437653,  2114119715,  2125266420,\n",
    "\t2134568281, 2141966705, 2230643224, 2237772889,  2270525613, 2277882633,  2298753937,  2298822749,  232455271,  2329327261,  2329390460, 2346672635,  2354271158,  2376789774,  2412869895,\n",
    "\t2430449524, 2449180071, 2449262679, 2560166191,  2565782704, 2580801517,  2594236668,  2617410370,  2652820441, 2662133688,  2681600918, 2686545520,  2745868322,  2750932731,  2761328098,\n",
    "\t2775871759, 2788766922, 279564179,  2799573282,  2838338304, 2848342961,  2877344705,  2896484227,  2928698519, 2942326,     2991315415, 3038173830,  3057951538,  3074864865,  3141177100,\n",
    "\t3160956615, 3163851319, 3177839472, 317893606,   3189404692, 3269177408,  3294873161,  3297669937,  3318440864, 3318770946,  3341420384, 3344016972,  3373725245,  3396594899,  3409866889,\n",
    "\t3443794754, 345746834,  349805344,  350075436,   3517002786, 356429972,   35662756,    358946176,   3592771178, 3601261162,  3601381760, 3668629268,  3726569889,  376626356,   3781237347,\n",
    "\t3782607913, 3792531352, 3793384814, 3793586357,  3806828901, 3871703326,  3924417156,  3947344563,  3948153992, 3995364020,  40050947,   401889419,   4029264216,  4038072487,  4050538978\n",
    "  ]\n",
    "```\n",
    "\n",
    "## ðŸ“˜ use and contact\n",
    "\n",
    "This notebook is part of a research or educational project.\n",
    "\n",
    "ðŸ‘€ Ensure that you have the necessary dependencies installed before running the notebook.\n",
    "\n",
    "To execute it successfully, you may need additional resources such as pretrained models or image datasets.\n",
    "\n",
    "If you would like access to these resources, please contact me at:\n",
    "lgabrielrojas@ucundinamarca.edu.co\n",
    "\n",
    "License & Usage Notice\n",
    "This notebook and its content are provided for academic and non-commercial purposes only, unless otherwise specified.\n",
    "Redistribution or usage of the data or models must be done with proper attribution and in accordance with any included license files.\n",
    "\n",
    "For collaborations, questions, or feedback, feel free to reach out via email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cd7aa",
   "metadata": {},
   "source": [
    "## LPIPS Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2577c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Only run this script if you have the necessary dependencies installed.\n",
    "try:\n",
    "\timport numpy as np\n",
    "except ImportError:\n",
    "\tprint(\"numpy is not installed. Please install it using the command below:\")\n",
    "\tprint(\"Installing numpy...\")\n",
    "\t! pip install numpy\n",
    "\tprint(\"numpy installed successfully.\")\n",
    "\n",
    "try:\n",
    "\timport lpips\n",
    "except ImportError:\n",
    "\tprint(\"lpips is not installed. Please install it using the command below:\")\n",
    "\tprint(\"Installing lpips...\")\n",
    "\t! pip install lpips\n",
    "\tprint(\"lpips installed successfully.\")\n",
    "\n",
    "try:\n",
    "\timport pandas as pd\n",
    "except ImportError:\n",
    "\tprint(\"pandas is not installed. Please install it using the command below:\")\n",
    "\tprint(\"Installing pandas...\")\n",
    "\t! pip install pandas\n",
    "\tprint(\"pandas installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a193bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import necessary libraries\n",
    "import lpips\n",
    "import re\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa39d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pricipal variables\n",
    "TEST_PATH = \"test\"\n",
    "LPIPS_RESULTS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0371ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\anaconda3\\envs\\infarct\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\anaconda3\\envs\\infarct\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: d:\\Anaconda\\anaconda3\\envs\\infarct\\Lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "LPIPS model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "#@title Load LPIPS model and loss function\n",
    "loss_fn = lpips.LPIPS(net='alex')  # 'alex', 'vgg', o 'squeeze' common choices\n",
    "print(\"LPIPS model loaded successfully.\")\n",
    "\n",
    "# Images transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Ajusta al tamaÃ±o esperado\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar entre -1 y 1\n",
    "])\n",
    "\n",
    "# Function to calculate LPIPS distance between two images\n",
    "def calculate_lpips(image1, image2):\n",
    "\t\t\"\"\"Calculate the LPIPS distance between two images.\n",
    "\t\tArgs:\n",
    "\t\t\timage1 (str): Path to the first image or a PIL Image.\n",
    "\t\t\timage2 (str): Path to the second image or a PIL Image.\n",
    "\t\tReturns:\n",
    "\t\t\tfloat: The LPIPS distance between the two images.\n",
    "\t\t\"\"\"\n",
    "\t\tif isinstance(image1, str):\n",
    "\t\t\timg1 = Image.open(image1).convert(\"RGB\")\n",
    "\t\telse:\n",
    "\t\t\timg1 = image1.convert(\"RGB\")\n",
    "\t\tif isinstance(image2, str):\n",
    "\t\t\timg2 = Image.open(image2).convert(\"RGB\")\n",
    "\t\telse:\n",
    "\t\t\timg2 = image2.convert(\"RGB\")\n",
    "\n",
    "\t\timg1 = transform(img1).unsqueeze(0)  # Add batch dimension\n",
    "\t\timg2 = transform(img2).unsqueeze(0)\n",
    "\t\t# distance LPIPS\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t\tdistance = loss_fn(img1, img2)\n",
    "\t\treturn distance.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa94410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 test images.\n",
      "Found 600 generated images.\n"
     ]
    }
   ],
   "source": [
    "#@title Prepare paths to evaluate images\n",
    "IMGS_TEST = os.path.join(TEST_PATH, \"Images_To_Test\")\n",
    "IMGS_GENE = os.path.join(TEST_PATH, \"Images_Generated\")\n",
    "images_test = [os.path.join(IMGS_TEST, f) for f in os.listdir(IMGS_TEST) if f.endswith(\".jpg\")][:10]\n",
    "print(f\"Found {len(images_test)} test images.\")\n",
    "images_generated = [os.path.join(IMGS_GENE, f) for f in os.listdir(IMGS_GENE) if f.endswith(\".png\")]\n",
    "print(f\"Found {len(images_generated)} generated images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2565b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPIPS calculated. Total: 6000\n"
     ]
    }
   ],
   "source": [
    "#@title Calculate LPIPS for each generated image against test images\n",
    "for img_test in images_test:\n",
    "    for img_gen in images_generated:\n",
    "\t\t\t\t# Get the model name from the generated image filename\n",
    "\t\t\t\t# For example, if the filename is sd-1.5-infarct-35662756.png, it should extract sd-1.5-infarct\n",
    "        model_name = re.search(r'sd-\\d\\.\\d-infarct(-lora)?', img_gen).group()\n",
    "        lpips_score = calculate_lpips(img_gen, img_test)\n",
    "        LPIPS_RESULTS.append((os.path.basename(img_test), os.path.basename(img_gen), model_name, lpips_score))\n",
    "print(\"LPIPS calculated. Total:\", len(LPIPS_RESULTS), \"comparisons made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3e7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Convert results to a DataFrame\n",
    "data = np.array(LPIPS_RESULTS)\n",
    "# Convertir el array a un DataFrame para un anÃ¡lisis mÃ¡s fÃ¡cil\n",
    "df = pd.DataFrame(data, columns=[\"id_test\", \"id_generada\", \"id_modelo\", \"score\"])\n",
    "df[\"score\"] = df[\"score\"].astype(float)  # Asegurar que los scores sean flotantes\n",
    "#df\n",
    "#@title Calculate average LPIPS score per model and test\n",
    "df_avg = df.groupby([\"id_test\", \"id_modelo\"])[\"score\"].mean().reset_index()\n",
    "#df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "044e4231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_test</th>\n",
       "      <th>sd-1.5-infarct</th>\n",
       "      <th>sd-1.5-infarct-lora</th>\n",
       "      <th>sd-2.1-infarct</th>\n",
       "      <th>sd-2.1-infarct-lora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TestInfarct (01).jpg</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.6498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TestInfarct (02).jpg</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.6471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TestInfarct (03).jpg</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.7108</td>\n",
       "      <td>0.6254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TestInfarct (04).jpg</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.7249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TestInfarct (05).jpg</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.7010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TestInfarct (06).jpg</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.7818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TestInfarct (07).jpg</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.6797</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TestInfarct (08).jpg</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.6679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TestInfarct (09).jpg</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TestInfarct (10).jpg</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.6969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_test  sd-1.5-infarct  sd-1.5-infarct-lora  sd-2.1-infarct  \\\n",
       "0  TestInfarct (01).jpg          0.6941               0.6478          0.7236   \n",
       "1  TestInfarct (02).jpg          0.6927               0.6486          0.7220   \n",
       "2  TestInfarct (03).jpg          0.6866               0.6207          0.7108   \n",
       "3  TestInfarct (04).jpg          0.7286               0.7109          0.7570   \n",
       "4  TestInfarct (05).jpg          0.7111               0.6917          0.7392   \n",
       "5  TestInfarct (06).jpg          0.7666               0.7730          0.7738   \n",
       "6  TestInfarct (07).jpg          0.6991               0.6797          0.7166   \n",
       "7  TestInfarct (08).jpg          0.6913               0.6689          0.7225   \n",
       "8  TestInfarct (09).jpg          0.7254               0.7303          0.7555   \n",
       "9  TestInfarct (10).jpg          0.7078               0.7067          0.7455   \n",
       "\n",
       "   sd-2.1-infarct-lora  \n",
       "0               0.6498  \n",
       "1               0.6471  \n",
       "2               0.6254  \n",
       "3               0.7249  \n",
       "4               0.7010  \n",
       "5               0.7818  \n",
       "6               0.7034  \n",
       "7               0.6679  \n",
       "8               0.7210  \n",
       "9               0.6969  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Data pivot\n",
    "pivot_df = df_avg.pivot(index=\"id_test\", columns=\"id_modelo\", values=\"score\")\n",
    "# Friendly column names\n",
    "pivot_df = pivot_df.reset_index()\n",
    "pivot_df.columns.name = None\n",
    "pivot_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807017cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of LPIPS results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sd-1.5-infarct</th>\n",
       "      <th>sd-1.5-infarct-lora</th>\n",
       "      <th>sd-2.1-infarct</th>\n",
       "      <th>sd-2.1-infarct-lora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.687835</td>\n",
       "      <td>0.736659</td>\n",
       "      <td>0.691920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.024415</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.045994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.686592</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.710799</td>\n",
       "      <td>0.625408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.693029</td>\n",
       "      <td>0.653685</td>\n",
       "      <td>0.722154</td>\n",
       "      <td>0.654290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.703405</td>\n",
       "      <td>0.685733</td>\n",
       "      <td>0.731399</td>\n",
       "      <td>0.698942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.721830</td>\n",
       "      <td>0.709840</td>\n",
       "      <td>0.753023</td>\n",
       "      <td>0.716605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.766611</td>\n",
       "      <td>0.773039</td>\n",
       "      <td>0.773814</td>\n",
       "      <td>0.781810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sd-1.5-infarct  sd-1.5-infarct-lora  sd-2.1-infarct  \\\n",
       "count       10.000000            10.000000       10.000000   \n",
       "mean         0.710317             0.687835        0.736659   \n",
       "std          0.024415             0.044768        0.020794   \n",
       "min          0.686592             0.620660        0.710799   \n",
       "25%          0.693029             0.653685        0.722154   \n",
       "50%          0.703405             0.685733        0.731399   \n",
       "75%          0.721830             0.709840        0.753023   \n",
       "max          0.766611             0.773039        0.773814   \n",
       "\n",
       "       sd-2.1-infarct-lora  \n",
       "count            10.000000  \n",
       "mean              0.691920  \n",
       "std               0.045994  \n",
       "min               0.625408  \n",
       "25%               0.654290  \n",
       "50%               0.698942  \n",
       "75%               0.716605  \n",
       "max               0.781810  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Results summary\n",
    "print(\"Summary of LPIPS results:\")\n",
    "pivot_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7659a",
   "metadata": {},
   "source": [
    "## Make your own evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81a8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports and path base\n",
    "from diffusers import DiffusionPipeline\n",
    "MODELS_PATH = \"models\"\n",
    "prompt = (\"Elderly man at a sports stadium surrounded by a crowd, \"\n",
    "\t\t\t\t\t\"clutching his chest with a distressed look, indicating a heart attack.\"\n",
    "\t\t\t\t)\n",
    "negative_prompt = (\n",
    "\t\t\t\t\t\"blurry, deformed face, bad anatomy, poorly drawn face, out of focus, ugly, noisy, extra fingers, \"\n",
    "\t\t\t\t\t\"distorted, grainy, worst quality, low quality, low resolution, illustration, \"\n",
    "\t\t\t\t\t\"dull, watermark, close-up, 3d, 2d, painting, sketch, render, cartoon, grain, kitsch\"\n",
    "\t\t\t\t)\n",
    "trigger = \"Person with expression of pain due to a heart attack, \"\n",
    "full_prompt = f\"{trigger}, {prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8359d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stable Diffusion v1.5 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:11<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stable Diffusion v2.1 model.\n",
      "Models moved to GPU.\n"
     ]
    }
   ],
   "source": [
    "#@title Load the pre-trained models\n",
    "sd15 = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "sd21 = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "\n",
    "sd15 = DiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True)\n",
    "print(\"Loaded Stable Diffusion v1.5 model.\")\n",
    "sd21 = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\", torch_dtype=torch.float16, use_safetensors=True)\n",
    "print(\"Loaded Stable Diffusion v2.1 model.\")\n",
    "# Move models to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "\t\tsd15.to(\"cuda\")\n",
    "\t\tsd21.to(\"cuda\")\n",
    "\t\tprint(\"Models moved to GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "824944c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [04:31<00:00,  6.80s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [04:14<00:00,  6.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPIPS SD 1.5 Score: 0.7341530323028564\n",
      "LPIPS SD 2.1 Score: 0.7580833435058594\n"
     ]
    }
   ],
   "source": [
    "#@title Evaluate base models with LPIPS\n",
    "image1 = [os.path.join(IMGS_TEST, f) for f in os.listdir(IMGS_TEST) if f.endswith(\".jpg\")][0]\n",
    "\n",
    "image_sd15 = sd15(prompt=full_prompt, negative_prompt=negative_prompt,\n",
    "\tguidance_scale=4, num_inference_steps=40).images[0]\n",
    "image_sd21 = sd21(prompt=full_prompt, negative_prompt=negative_prompt,\n",
    "\tguidance_scale=4, num_inference_steps=40).images[0]\n",
    "\n",
    "# Calculate distance LPIPS\n",
    "lpips_score = calculate_lpips(image1, image_sd15)\n",
    "print(f\"LPIPS SD 1.5 Score: {lpips_score}\")\n",
    "lpips_score = calculate_lpips(image1, image_sd21)\n",
    "print(f\"LPIPS SD 2.1 Score: {lpips_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b51213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LoRA weights for SD 1.5\n",
      "Loaded LoRA weights for SD 2.1\n",
      "Moving models to GPU\n"
     ]
    }
   ],
   "source": [
    "#@title Load LoRA tunning weights\n",
    "sd15.load_lora_weights(\"models/sd-1.5-infarct-000010.safetensors\")\n",
    "print(\"Loaded LoRA weights for SD 1.5\")\n",
    "sd21.load_lora_weights(\"models/sd-2.1-infarct-000010.safetensors\")\n",
    "print(\"Loaded LoRA weights for SD 2.1\")\n",
    "# Move models to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "\tprint(\"Moving models to GPU\")\n",
    "\tsd15.to(\"cuda\")\n",
    "\tsd21.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b397fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [06:20<00:00,  9.51s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [05:06<00:00,  7.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPIPS SD 1.5 with LoRA Score: 0.6756401062011719\n",
      "LPIPS SD 2.1 with LoRA Score: 0.6637046337127686\n"
     ]
    }
   ],
   "source": [
    "#@title Evaluate LoRA models with LPIPS\n",
    "image1 = [os.path.join(IMGS_TEST, f) for f in os.listdir(IMGS_TEST) if f.endswith(\".jpg\")][0]\n",
    "\n",
    "image_sd15_lora = sd15(prompt=full_prompt, negative_prompt=negative_prompt,\n",
    "\tguidance_scale=4, num_inference_steps=40).images[0]\n",
    "image_sd21_lora = sd21(prompt=full_prompt, negative_prompt=negative_prompt,\n",
    "\tguidance_scale=4, num_inference_steps=40).images[0]\n",
    "\n",
    "# Calculate distance LPIPS\n",
    "lpips_score = calculate_lpips(image1, image_sd15_lora)\n",
    "print(f\"LPIPS SD 1.5 with LoRA Score: {lpips_score}\")\n",
    "lpips_score = calculate_lpips(image1, image_sd21_lora)\n",
    "print(f\"LPIPS SD 2.1 with LoRA Score: {lpips_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infarct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
